spark.executor.memory=<%= ENV["SPARK_EXECUTOR_MEMORY"] || '12g' %>
spark.driver.memory=<%= ENV["SPARK_DRIVER_MEMORY"] || '2g' %>
spark.deploy.defaultCores=<%= ENV["SPARK_DEFAULT_CORES"] || '4' %>
spark.executor.extraClassPath=/app/spark-home/lib/hadoop-aws-shaded.jar:/app/spark-home/lib/hadoop-lzo.jar
spark.driver.extraClassPath=/app/spark-home/lib/hadoop-aws-shaded.jar:/app/spark-home/lib/hadoop-lzo.jar
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.s3a.S3A
spark.hadoop.fs.s3n.impl=org.apache.hadoop.fs.s3native.NativeS3FileSystem
spark.hadoop.fs.s3n.multipart.uploads.block.size=536870912
spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec
spark.hadoop.io.compression.codec.lzo.class=com.hadoop.compression.lzo.LzoCodec


<% if ENV["SPARK_S3_AWS_ACCESS_KEY_ID"] && ENV["SPARK_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3a.awsAccessKeyId=<%= ENV["SPARK_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3a.awsSecretAccessKey=<%= ENV["SPARK_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3a.access.key=<%= ENV["SPARK_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3a.secret.key=<%= ENV["SPARK_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3n.awsAccessKeyId=<%= ENV["SPARK_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3n.awsSecretAccessKey=<%= ENV["SPARK_S3_AWS_SECRET_ACCESS_KEY"] %>
spark.hadoop.fs.s3n.access.key=<%= ENV["SPARK_S3_AWS_ACCESS_KEY_ID"] %>
spark.hadoop.fs.s3n.secret.key=<%= ENV["SPARK_S3_AWS_SECRET_ACCESS_KEY"] %>
<% end %>
